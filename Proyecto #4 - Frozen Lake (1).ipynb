{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1Iflh_Jrlpg4hE0pOvjAu8US6Hl3Ao_jR","timestamp":1686760894054},{"file_id":"11tQCT2EAbpUy_Z6E0hziUyF0Q-fCECDV","timestamp":1686675064287}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### Instalamos e importamos tanto las librerías como el FrozenLake v0"],"metadata":{"id":"09hmyJ6TyWN-"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"koPJLNEo9edr","executionInfo":{"status":"ok","timestamp":1686676667780,"user_tz":-120,"elapsed":5693,"user":{"displayName":"Augusto Bonomo","userId":"06991271049294275439"}},"outputId":"a006b7a3-ccff-44a1-9dbd-b08b7f3f3312"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: gym==0.17.3 in /usr/local/lib/python3.10/dist-packages (0.17.3)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from gym==0.17.3) (1.10.1)\n","Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.10/dist-packages (from gym==0.17.3) (1.22.4)\n","Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from gym==0.17.3) (1.5.0)\n","Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym==0.17.3) (1.6.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym==0.17.3) (0.18.3)\n"]}],"source":["!pip install gym==0.17.3"]},{"cell_type":"code","source":["import gym\n","import numpy as np\n","import random as rd\n","from IPython.display import clear_output\n","\n","env = gym.make('FrozenLake-v0', desc=None, map_name=\"4x4\", is_slippery=False)"],"metadata":{"id":"5Sve0TcH9koh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Visualizamos el espacio de 4x4 y ejecutamos la tabla de recompensas"],"metadata":{"id":"dEjkiyNoyfK0"}},{"cell_type":"code","source":["env.reset()\n","env.render()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JJmGU2jx9nlV","executionInfo":{"status":"ok","timestamp":1686676667781,"user_tz":-120,"elapsed":27,"user":{"displayName":"Augusto Bonomo","userId":"06991271049294275439"}},"outputId":"29b09459-6b4e-4368-b890-a6ece4fd417f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\u001b[41mS\u001b[0mFFF\n","FHFH\n","FFFH\n","HFFG\n"]}]},{"cell_type":"code","source":["print(\"Action Space {}\".format(env.action_space))\n","print(\"State Space {}\".format(env.observation_space))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fi48QJxk9rJv","executionInfo":{"status":"ok","timestamp":1686676667781,"user_tz":-120,"elapsed":24,"user":{"displayName":"Augusto Bonomo","userId":"06991271049294275439"}},"outputId":"78821010-31a8-4c0a-a2d3-8516d21a4a5c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Action Space Discrete(4)\n","State Space Discrete(16)\n"]}]},{"cell_type":"code","source":["#Tabla de recompensa\n","\n","env.P"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c95kPLa19ufX","executionInfo":{"status":"ok","timestamp":1686676667781,"user_tz":-120,"elapsed":23,"user":{"displayName":"Augusto Bonomo","userId":"06991271049294275439"}},"outputId":"4fb2d00c-3021-4c8b-df26-b6c043167f3a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{0: {0: [(1.0, 0, 0.0, False)],\n","  1: [(1.0, 4, 0.0, False)],\n","  2: [(1.0, 1, 0.0, False)],\n","  3: [(1.0, 0, 0.0, False)]},\n"," 1: {0: [(1.0, 0, 0.0, False)],\n","  1: [(1.0, 5, 0.0, True)],\n","  2: [(1.0, 2, 0.0, False)],\n","  3: [(1.0, 1, 0.0, False)]},\n"," 2: {0: [(1.0, 1, 0.0, False)],\n","  1: [(1.0, 6, 0.0, False)],\n","  2: [(1.0, 3, 0.0, False)],\n","  3: [(1.0, 2, 0.0, False)]},\n"," 3: {0: [(1.0, 2, 0.0, False)],\n","  1: [(1.0, 7, 0.0, True)],\n","  2: [(1.0, 3, 0.0, False)],\n","  3: [(1.0, 3, 0.0, False)]},\n"," 4: {0: [(1.0, 4, 0.0, False)],\n","  1: [(1.0, 8, 0.0, False)],\n","  2: [(1.0, 5, 0.0, True)],\n","  3: [(1.0, 0, 0.0, False)]},\n"," 5: {0: [(1.0, 5, 0, True)],\n","  1: [(1.0, 5, 0, True)],\n","  2: [(1.0, 5, 0, True)],\n","  3: [(1.0, 5, 0, True)]},\n"," 6: {0: [(1.0, 5, 0.0, True)],\n","  1: [(1.0, 10, 0.0, False)],\n","  2: [(1.0, 7, 0.0, True)],\n","  3: [(1.0, 2, 0.0, False)]},\n"," 7: {0: [(1.0, 7, 0, True)],\n","  1: [(1.0, 7, 0, True)],\n","  2: [(1.0, 7, 0, True)],\n","  3: [(1.0, 7, 0, True)]},\n"," 8: {0: [(1.0, 8, 0.0, False)],\n","  1: [(1.0, 12, 0.0, True)],\n","  2: [(1.0, 9, 0.0, False)],\n","  3: [(1.0, 4, 0.0, False)]},\n"," 9: {0: [(1.0, 8, 0.0, False)],\n","  1: [(1.0, 13, 0.0, False)],\n","  2: [(1.0, 10, 0.0, False)],\n","  3: [(1.0, 5, 0.0, True)]},\n"," 10: {0: [(1.0, 9, 0.0, False)],\n","  1: [(1.0, 14, 0.0, False)],\n","  2: [(1.0, 11, 0.0, True)],\n","  3: [(1.0, 6, 0.0, False)]},\n"," 11: {0: [(1.0, 11, 0, True)],\n","  1: [(1.0, 11, 0, True)],\n","  2: [(1.0, 11, 0, True)],\n","  3: [(1.0, 11, 0, True)]},\n"," 12: {0: [(1.0, 12, 0, True)],\n","  1: [(1.0, 12, 0, True)],\n","  2: [(1.0, 12, 0, True)],\n","  3: [(1.0, 12, 0, True)]},\n"," 13: {0: [(1.0, 12, 0.0, True)],\n","  1: [(1.0, 13, 0.0, False)],\n","  2: [(1.0, 14, 0.0, False)],\n","  3: [(1.0, 9, 0.0, False)]},\n"," 14: {0: [(1.0, 13, 0.0, False)],\n","  1: [(1.0, 14, 0.0, False)],\n","  2: [(1.0, 15, 1.0, True)],\n","  3: [(1.0, 10, 0.0, False)]},\n"," 15: {0: [(1.0, 15, 0, True)],\n","  1: [(1.0, 15, 0, True)],\n","  2: [(1.0, 15, 0, True)],\n","  3: [(1.0, 15, 0, True)]}}"]},"metadata":{},"execution_count":100}]},{"cell_type":"markdown","source":["### Definimos la posición de salida, que será desde el mismo lugar"],"metadata":{"id":"Bn5snunmypF9"}},{"cell_type":"code","source":["state = env.s\n","print(\"State:\", state)  #En este caso siempre empezará de la posición zero"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3JbE29lp97ZQ","executionInfo":{"status":"ok","timestamp":1686676667781,"user_tz":-120,"elapsed":21,"user":{"displayName":"Augusto Bonomo","userId":"06991271049294275439"}},"outputId":"3945bf92-b504-4bae-928b-e8e86bc15c8a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["State: 0\n"]}]},{"cell_type":"code","source":["#Movimientos desde la posición 0\n","\n","env.P[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C0UPX2aL-kWn","executionInfo":{"status":"ok","timestamp":1686676667782,"user_tz":-120,"elapsed":20,"user":{"displayName":"Augusto Bonomo","userId":"06991271049294275439"}},"outputId":"e5c09dc8-77de-443b-b3da-60709c9a6159"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{0: [(1.0, 0, 0.0, False)],\n"," 1: [(1.0, 4, 0.0, False)],\n"," 2: [(1.0, 1, 0.0, False)],\n"," 3: [(1.0, 0, 0.0, False)]}"]},"metadata":{},"execution_count":102}]},{"cell_type":"markdown","source":["##Action Space:\n","\n","\n","\n","*   0: Left\n","*   1: Down\n","*   2: Right\n","*   3: Up"],"metadata":{"id":"ExDe9Y2C-1dE"}},{"cell_type":"markdown","source":["##Rewards:\n","\n","*   Reach goal(G): +1\n","*   Reach hole(H): 0\n","*   Reach frozen(F): 0"],"metadata":{"id":"je5YWL-E-1az"}},{"cell_type":"markdown","source":["##Definimos tabla Q"],"metadata":{"id":"pXYlUxswBEu1"}},{"cell_type":"code","source":["q_table = np.zeros([env.observation_space.n, env.action_space.n])"],"metadata":{"id":"NRhUrWhZ-1Yk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["q_table[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V2SCAK8dFO_w","executionInfo":{"status":"ok","timestamp":1686676667782,"user_tz":-120,"elapsed":19,"user":{"displayName":"Augusto Bonomo","userId":"06991271049294275439"}},"outputId":"2ef090f8-af32-4e27-b2e8-c08f67ec7f2e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0., 0., 0., 0.])"]},"metadata":{},"execution_count":104}]},{"cell_type":"markdown","source":["##Definimos greedy policy"],"metadata":{"id":"YCUrLzt8-1U7"}},{"cell_type":"code","source":["def greedy(epsilon,q_table,state,env):\n","    if rd.random() < epsilon:\n","        action=env.action_space.sample() #explorar\n","    else:\n","        action=np.argmax(q_table[state]) #explotar\n","    return action"],"metadata":{"id":"SBsmb53v-1Sp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Entrenamos y ejecutamos el programa"],"metadata":{"id":"7YLK5SeMzIEO"}},{"cell_type":"code","source":["# Definimos los Hyperparameters\n","\n","alpha = 0.7 # tasa de aprendizaje\n","gamma = 0.95 # tasa de descuento\n","epsilon = 1.0 # greedy policy\n","\n","# Generamos las listas vacías para agrupar los resultados\n","all_timestep = []\n","all_penalties = []\n","\n","# Definimos la cantidad de episodios que realizaremos\n","episodes = 1001\n","\n","for i in range(episodes):\n","    state = env.reset()\n","\n","    timestep, penalties, reward = 0, 0, 0\n","    done = False\n","\n","    while not done:\n","        action = greedy(epsilon,q_table,state,env) # aplicamos la greedy policy\n","\n","        next_state, reward, done, info = env.step(action) # tomamos la acción elegida\n","\n","        old_value = q_table[state, action] # en la Q-table, tomamos el valor Q de la acción elegida para el estado actual\n","        next_max = np.max(q_table[next_state]) # en la Q-table, tomamos el máximo entre los valores Q para el nuevo estado\n","\n","        new_value = (1 - alpha) * old_value + alpha * (reward + gamma * next_max) # actualizamos el valor Q\n","        q_table[state, action] = new_value\n","\n","        if reward == 0:\n","            penalties += 1\n","\n","        state = next_state\n","        timestep += 1\n","\n","    if i % 100 == 0:\n","        clear_output(wait=True)\n","        print(f\"Episode: {i}\")\n","\n","print(\"Training finished.\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iHOWfynk-1Qi","executionInfo":{"status":"ok","timestamp":1686676668213,"user_tz":-120,"elapsed":448,"user":{"displayName":"Augusto Bonomo","userId":"06991271049294275439"}},"outputId":"6b778417-1173-4a64-f987-2eb4a6965b9c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Episode: 1000\n","Training finished.\n","\n"]}]},{"cell_type":"code","source":["env.s\n","env.render()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jCf4LZknCwgs","executionInfo":{"status":"ok","timestamp":1686676668213,"user_tz":-120,"elapsed":12,"user":{"displayName":"Augusto Bonomo","userId":"06991271049294275439"}},"outputId":"1de0973c-247f-4b04-9f33-c2c226d29117"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  (Right)\n","SFFF\n","F\u001b[41mH\u001b[0mFH\n","FFFH\n","HFFG\n"]}]},{"cell_type":"code","source":["q_table #Visualizamos los valores del Q_table"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IcfzIy07Cy7y","executionInfo":{"status":"ok","timestamp":1686676668214,"user_tz":-120,"elapsed":12,"user":{"displayName":"Augusto Bonomo","userId":"06991271049294275439"}},"outputId":"cd8f302e-e89f-4469-b028-ae8d5bff96a0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.73509164, 0.77378067, 0.77378053, 0.73509164],\n","       [0.73509164, 0.        , 0.81450582, 0.77378051],\n","       [0.77378032, 0.85737469, 0.7737798 , 0.81450563],\n","       [0.81450506, 0.        , 0.77377803, 0.77377975],\n","       [0.77378062, 0.81450597, 0.        , 0.73509161],\n","       [0.        , 0.        , 0.        , 0.        ],\n","       [0.        , 0.90249971, 0.        , 0.8145026 ],\n","       [0.        , 0.        , 0.        , 0.        ],\n","       [0.81450594, 0.        , 0.85737471, 0.77378064],\n","       [0.81450578, 0.9024978 , 0.90249971, 0.        ],\n","       [0.85737469, 0.9499998 , 0.        , 0.85735857],\n","       [0.        , 0.        , 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.        ],\n","       [0.        , 0.89605336, 0.94999835, 0.8573433 ],\n","       [0.90236487, 0.94983622, 0.99999995, 0.90238926],\n","       [0.        , 0.        , 0.        , 0.        ]])"]},"metadata":{},"execution_count":108}]},{"cell_type":"code","source":["class bcolors:\n","    RED= '\\u001b[31m'\n","    GREEN= '\\u001b[32m'\n","    RESET= '\\u001b[0m'\n","\n","env.s = 0\n","state = env.reset()\n","done = False\n","\n","timestep, penalties, reward = 0, 0, 0\n","total_reward = 0\n","\n","while not done:\n","\n","  action = np.argmax(q_table[state])\n","  state, reward, done, info = env.step(action) # con \"step\" realizamos la acción elegida\n","\n","  if reward == 0:\n","      penalties += 1 # sumamos una penalización si el taxi intenta dejar al pasajero cuando aún no está a bordo\n","\n","  timestep += 1\n","  total_reward += reward\n","\n","  # Print each step\n","  clear_output(wait=True)\n","  env.render()\n","  print(\"\")\n","  if reward == 0:\n","    print(f\"Recompensa actual: {bcolors.RED}{reward}{bcolors.RESET}\")\n","  else:\n","    print(f\"Recompensa actual: {bcolors.GREEN}{reward}{bcolors.RESET}\")\n","  if reward == 0:\n","    print(f\"Recompensa total: {bcolors.RED}{total_reward}{bcolors.RESET}\")\n","  else:\n","    print(f\"Recompensa total: {bcolors.GREEN}{total_reward}{bcolors.RESET}\")\n","  print(\"\")\n","  print('Estado actual', state)\n","\n","print(\"Timesteps taken: {}\".format(timestep))\n","print(\"Penalties incurred: {}\".format(penalties))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lKxCGeDzC6r5","executionInfo":{"status":"ok","timestamp":1686676668214,"user_tz":-120,"elapsed":11,"user":{"displayName":"Augusto Bonomo","userId":"06991271049294275439"}},"outputId":"e494536c-cf5f-4aef-8198-a4b9e0325b99"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  (Right)\n","SFFF\n","FHFH\n","FFFH\n","HFF\u001b[41mG\u001b[0m\n","\n","Recompensa actual: \u001b[32m1.0\u001b[0m\n","Recompensa total: \u001b[32m1.0\u001b[0m\n","\n","Estado actual 15\n","Timesteps taken: 6\n","Penalties incurred: 5\n"]}]}]}